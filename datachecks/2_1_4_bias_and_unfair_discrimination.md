
# Data Check - Thematic area: Bias and Unfair Discrimination

## Definitions

Bias: is defined as a prejudice for - or against - an individual or group in a way that is oftentimes unfair. Bias arises from the human tendency to classify people into groups according to certain characteristics (e.g. race, gender, nationality, class, etc.) and different levels of power, status, and resources they generally hold. These classifications can lead to judgments about individuals based on the level of power, status, and resources they are presumed to have based on these characteristics and association with particular groups. Biases are often reinforced in relationships, communities, institutions, and the broader society, including both public and private sector institutions.

Algorithmic bias: is defined as systematic and repeatable errors in an AI-powered system that create unfair outcomes, such as privileging one group over others. Algorithmic bias can arise from unrepresentative or incomplete data or the reliance on flawed information that reflects historic and/or current inequalities. This can lead to decisions that have a discriminatory impact on certain individuals or groups of people regardless of whether there was an intent to discriminate. This can result in the disproportionate allocation of opportunities, resources and information, including access to social and economic rights, violation of human rights, prioritisation of the safety and well-being of certain individuals at the expense of others, and legitimisation of discriminatory practices.

Discrimination: is defined as the practice of treating an individual or group of people in a way that is different to others because of their age, disability, gender, race, sexuality, or other characteristic. Unfair discrimination is the practice of treating an individual or group of people in a way that is unjustifiable because it is not intended to achieve greater levels of equity or advance members of a previously disadvantaged group. It is important to note that not all forms of discrimination are unfair, meaning that some forms of discrimination can be used to advance greater levels of equity, (such as providing preferential treatment to female candidates in STEM programs), while others can be used to perpetuate certain forms of harms, (such as surveillance of political dissidents).

The right to be free from unfair discrimination is protected under the right to equality, which is the foundational principle embedded across various international human rights instruments and legal standards. Article 2 of the Universal Declaration of Human Rights, 1948, provides that ‘[e]veryone is entitled to all the rights and freedoms set forth in this Declaration without distinction of any kind, such as race, color, sex, language, religion, political or other opinion, national or social origin, property, birth or other status’. Key instruments also include the International Covenant on the Elimination of All Forms of Racial Discrimination (ICEARD), which entitles all human beings to equal protection against any discrimination and against any incitement to discrimination (Article 1); the International Covenant on Civil and Political Rights (ICCPR), which calls for the full and equal and enjoyment of all civil and political rights, including the right to non-discrimination (Article 26); and the International Covenant on Economic, Social and Cultural Rights (ICESCR), which provides for the right to equal access to basic services, infrastructure and in enjoyment of the benefits of scientific progress and applications, including digital inclusion (Article 15). Additionally, national frameworks are likely to provide clarity on what the right to non-discrimination means in each country; what definitions/concepts of fairness exist in the country, and what remedies are available to individuals if their rights are violated.

## Identifications

This thematic area examines steps countries have taken to prevent and mitigate the risk of unfair discrimination posed by biases in the design, development and use of AI. In particular, evidence must account for (1) frameworks aimed to reduce bias and unfair discrimination of AI systems, (2) government actions to implement these frameworks or address relating to bias and unfair discrimination, and (3) non-state actors working to reduce bias and unfair discrimination in the use of AI systems across the country. .
Frameworks may take the form of laws, regulations, policies (including by sector and/or department), and/or guidelines. Government actions may include draft laws and frameworks, the establishment of expert working groups to provide g policy recommendations on the issue, or the establishment of oversight bodies responsible for overseeing compliance with laws and regulations that aim to prevent bias and discrimination in the rollout of AI systems. Non-state actors (NSAs) may include non-governmental organisations (NGOs), but also multinational corporations, private military organisations, media outlets, organised ethnic groups, academic institutions, lobby groups, labour unions or social movements working to reduce bias and unfair discrimination in the design, development and deployment of AI systems.


## Some Examples:

### Frameworks:

In the U.K., the National Data Strategy calls upon private organisations to specifically address “biases arising from data or algorithm use” based on an identification in the Center for Data Ethics and Innovation (CDEI)’s interim report.

### Government Actions

In 2018, the U.K. Government founded the CDEI to provide policy recommendations for ethical use of AI and other data-driven technologies. That same year, it commissioned the centre to conduct two policy reviews, including on algorithmic bias. According to its plan, the CDEI investigated algorithmic bias in four sectors including policing, local government, financial services and recruitment. In June 2022, the CDEI launched a new programme in response to these findings which will include specific focus on “exploring the potential for novel approaches to data stewardship to support organisations to access demographic data to monitor their products and services for algorithmic bias.”

### Non-state Actors

In the non-state sector, the U.S.-based Algorithmic Justice League recognises AI’s potential for perpetuating different forms of discrimination as a result of bias and works to raise public awareness using a combination of art and research as well as to “equip advocates with resources to bolster campaigns, build the voice and choice of the most impacted communities, and galvanize researchers, policymakers, and industry practitioners to prevent AI harms.” Alongside its ongoing research, the organisation has released a documentary called ‘Coded Bias’, hosted a ‘Drag vs. AI Workshop’ and run the multi-stakeholder project Community Reporting of Algorithmic System Harms.

## Search Term Guidance Helper

- Parliamentary or government records for recent mentions of ‘bias and AI’, ‘non-discrimination and AI’, ‘representation and AI’, ‘equality and AI’,

- Other key search terms include key terms ‘minority rights’ and/or ‘indigenous rights’ with respect to AI/digital technologies and bias.
