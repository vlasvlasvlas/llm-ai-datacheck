
# Data Check - Thematic area: Responsible AI Research & Development


## Definitions

Research and Development (R&D) can be defined as the activities that entities (public or private sector) undertake to innovate and introduce new products or services, which is often for the purpose of improving their existing offerings. R&D is typically the first stage of the development process and is exploratory in nature in that it is separate from the operational activities of a business and therefore not immediately focused on profits.
Responsible AI, as it is commonly understood, is an approach to designing, developing and deploying in a safe, trustworthy and ethical manner. Proponents of responsible AI advocate for the widespread adoption of ethical AI principles and practices to ensure the development of AI technologies are human-centred, interpretable and explainable, and to establish systems that promote transparency, reliability and fairness.
Accordingly, responsible AI R&D, can be understood as the activities that entities, including both public and private sector organisations, undertake to explore and innovate new AI technologies that conform to and align with responsible AI principles.

## Identifications

This thematic area measures steps countries have taken to invest in responsible AI R&D. In particular, evidence must account for (1) frameworks relating to policies, programmes or guidelines that outline funding and practices for responsible AI R&D (2) government actions to support responsible AI R&D by investing programmes that focus on the integration of responsible AI systems across government departments, agencies and functions, building of research networks, funds or tenders that focus on responsible AI R&D, and (3) non-state actors working to advance responsible AI R&D by engaging in efforts to promote and support the development of AI technologies to advance human rights, to establish networks of practitioners and researchers working on responsible AI R&D, and advocacy efforts to investment in responsible AI R&D is a priority.

Frameworks may take the form of adopted policies, white papers, or guidelines. Government actions can encompass the creation of draft policies or guidelines, the formation of government entities like oversight bodies tasked with providing policy recommendations on responsible AI R&D and/or ensuring the allocation of funding towards responsible AI R&D. Additionally, these actions can involve the execution of policies aimed at addressing the issue and/or promoting awareness or collecting more data about responsible AI R&D. Non-state actors (NSAs) may include non-governmental organisations (NGOs), but also multinational corporations, private military organisations, media outlets, organised ethnic groups, academic institutions, lobby groups, labour unions or social movements working to advance investment in responsible AI R&D is a priority.


## Some Examples:

### Frameworks examples:

The European Commission’s research and innovation policy on AI focuses on the following four priorities: (1) developing and deploying AI solutions that have positive impacts on society and the economy; (2) increasing and prioritising public and private investments (including better access to and use of scientific data); (3) promoting the development of Trustworthy AI by prompting ethics by design in Horizon Europe research and innovation projects; and (4) funding research and innovation projects in AI underpinning the industrial transition.

### Government Actions examples:

In 2020, the European Commission invested €1.5 billion in AI, with the aim to mobilise public and private sector resources to accelerate deployment of AI by a range of stakeholders, including small and medium-sized enterprises. By the end of 2020, the Commission aimed to increase the total investment in AI from both the public and private sector to €20 billion per year to support the continuous funding of AI R&D through Horizon Europe(the EU’s research and innovation funding programme) and Digital Europe programmes across the region.

### Non-state Actors examples:

The Stockholm International Peace Research Institute (SIPRI) is an independent international research institute based in Sweden that specialises in conflict, arms control and disarmament. SIPRI provides data, analysis and recommendations to policymakers, researchers, media and the general public on emerging trends, threats and innovations in international security, including developments in AI. SIPRI’s has been supported by the European Commission to conduct research on: (a) how AI may find uses in conventional, cyber and nuclear force related systems; (b) how military use of AI might create humanitarian but also strategic risks, and opportunities, for arms control and export verification; and (c) how the risks posed by AI may be governed through international law, arms control process and responsible research and innovation.


## Search Term Guidance Helper

- Helpful alternative search terms may include "responsible AI R&D," "investment in AI R&D", and “innovations in responsible AI R&D”