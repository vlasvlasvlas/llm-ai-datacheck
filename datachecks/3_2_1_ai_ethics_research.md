
# Data Check - Thematic area: AI Ethics Research


## Definitions

Ethics can be defined as ‘a set of moral principles that govern a person’s behavior or the conducting of a particular activity'. In this regard, ethics can be thought of as a set of principles based on notions of right and wrong that help determine what constitutes acceptable and unacceptable conduct and/or behavior. AI Ethics can therefore be defined as ‘a system of moral principles and techniques’ intended to guide the design, development, use and deployment of AI technologies. While standards for AI Ethics are always evolving, the UNESCO Recommendation on the Ethics of Artificial Intelligence (Recommendation) has articulated four core values underlying ethical AI: (1) human rights and human dignity; (2) living in peaceful, just and interconnected societies; (3) ensuring diversity and inclusiveness; and (4) environment and ecosystem flourishing. In addition, the Organisation for Economic Cooperation and Development (OECD) has identified five value-based principles for AI, which include: (1) inclusive growth, sustainable development and well-being; (2) human-centred values and fairness; (3) transparency and explainability; (4) robustness, security and safety; and (5) accountability. AI Ethics Research is an emerging field of study within applied ethics and the philosophy of technology concerned with how ethical principles are currently applied to AI and whether they serve as adequate safeguards against some of the risks posed by the development and deployment of AI systems and tools.

## Identifications

This thematic area measures steps countries have taken to invest in AI Ethics Research. In particular, evidence must account for (1) frameworks relating to policies, programmes or guidelines that outline funding and practices of AI Ethics Research (2) government actions to support AI Ethics Research by investing programmes that focus on the integration of AI ethics across government departments, agencies and functions, building of research networks, funds or tenders that focus on AI Ethics Research, and (3) non-state actors working to advance AI ethics by the establishment of independent research networks or institutes for AI Ethics Research Units, publications in that area or funding streams dedicated to AI Ethics. Frameworks may take the form of adopted policies, white papers, or guidelines. Government actions can encompass the creation of draft policies or guidelines, the formation of government entities like oversight bodies tasked with providing policy recommendations on the matter and/or enforcing regulations. Additionally, these actions can involve the execution of policies aimed at addressing the issue and/or promoting awareness or collecting more data about AI Ethics Research. Non-state actors (NSAs) may include non-governmental organisations (NGOs), but also multinational corporations, private military organisations, media outlets, organised ethnic groups, academic institutions, lobby groups, labour unions or social movements working to advance the relevance and importance of AI ethics research.


## Some Examples:

### Frameworks examples:

The German federal government outlined in an AI-Strategy that a joint European networking approach should be used to foster research ‘when it comes to establishing clear ethical guidelines, in basic and applied research in the medium and long term’. In the strategy the government also advocates for an ‘ethics by design’ approach [focusing on technical solutions] and in general committed to provide EUR 5 billion by 2025 for the promotion of AI. But, one has to be aware of the distinction between general research into AI applications versus those specifically targeted to AI Ethics Research.

### Government Actions examples:

Government action visible is for example the financing of competence centers for AI that are funded by the German Ministry for Education and Research and participating federal states and the DFKI (one of those centers) which also has an AI Ethics team. Moreover, through the German Research Foundation single projects are funded, for example, the paper from Thilo Hagendorff (2022) ‘Blind spots in AI ethics’ by the Cluster of Excellence Machine Learning—New Perspectives for Science.

### Non-state Actors examples:

There are civil society organizations like Algorithm Watch specifically committed ‘to watch, unpack and analyze automated decision-making (ADM) systems and their impact on society’ and produced for example a global database of 167 ethics guidelines. Moreover, the Bertelsmann Stiftung (foundation) runs a project on Ethics of Algorithms with what they want to contribute to a ‘design of algorithmic systems that leads to more participation for all’. In 2019, Meta provided an initial funding grant required for the founding of the Institute for Ethics in Artificial Intelligence at Munich University.


## Search Term Guidance Helper

- Helpful alternative search terms may include "AI Ethics Research," "researching AI Ethics", “Ethical AI” and “Ethical Automated Decision Making”.