
# Data Check - Thematic area: Institutional Oversight of AI


## Definitions

Institutional oversight can be defined as ‘the actions taken to review and monitor public sector organisations and their policies, plans, programs and projects so that they: (1) are achieving expected results; (2) represent good value for money; and (3) are in compliance with applicable policies, laws, regulations and ethical standards’. Oversight, in this regard, means ‘looking over’ but not touching, which in turn, requires those in charge of oversight functions to observe processes, programs, or projects from above, but not to get involved in the day-to-day management or to interfere in its operations. Although institutional oversight often arises in discussions about the conduct of public entities and agencies, oversight can be extended to non-state actors, including private sector companies, civil society organisations, and academic institutions. In this regard, oversight can be treated as a core function of governance performed by boards of directors, committees, councils and/or other external bodies.

## Identifications

This thematic area measures steps countries have taken to support institutional oversight over the design, development, use and deployment of AI technologies. In particular, evidence must account for (1) frameworks relating to oversight mechanisms and relevant authorities, including data protection authorities, and their power to oversee the development and deployment of AI systems and tools, (2) government actions to develop, implement and/or support the work of oversight agencies or oversight mechanisms for AI, and (3) non-state actors working to advance institutional oversight over every phase of the AI lifecycle. Frameworks may take the form of adopted laws, policies, regulations, white papers, or guidelines. Government actions may include the development of draft laws and/or policies, the establishment of oversight bodies which may be independent or external to government, or the creation of an expert working group that is conducting research on which oversight mechanisms are best placed to assist the country in conducting institutional oversight over the development and deployment of AI technologies. Non-state actors (NSAs) may include non-governmental organisations (NGOs), but also multinational corporations, private military organisations, media outlets, organised ethnic groups, academic institutions, lobby groups, labour unions or social movements working to advance independent mechanisms for institutional oversight over AI developers, implementers, or users


## Some Examples:

### Frameworks examples:

The Personal Data Protection Commission in Singapore released the 2nd Edition of the Model Artificial Intelligence Governance Framework (Framework) in January 2020. The Framework calls for internal governance structures and measures ‘that allow organisations to have appropriate oversight over how AI technologies are brought into their operations and/or products and services’ and ‘help to ensure robust oversight over an organisation’s use of AI’. More specifically, this calls for ‘responsibility for and oversight of the various stages and activities involved in AI deployment should be allocated to the appropriate personnel and/or departments’ which may necessitate the establishment of ‘a coordinating body, having relevant expertise and proper representation from across the organisation’.

### Government Actions examples:

Singapore’s Personal Data Protection Commission (PDPC) is responsible for conducting institutional oversight of AI developers and AI-using companies specifically in relation to their use of personal data, which consists of backroom operations, front-end usage companies, and distributors of equipment with AI features. In addition, the Singapore Academy of Law (SAL) conducts oversight of laws applicable to AI systems and has the authority to make decisions on issues that impact the AI industry.

### Non-state Actors examples:

In April 2020, the National University of Singapore launched the Centre on AI Technology for Humankind (AiTH), which ‘champions a behavioural human-centred approach to AI’ that supports efforts to ensure AI ‘is designed and employed in ways that are experienced as genuinely supporting and complementary to human endeavours’. Part of its work involves releasing publications that discuss the importance of institutional oversight of AI and the risks that arise when the appropriate accountability mechanisms are not in place.


## Search Term Guidance Helper

- Helpful alternative search terms may include "AI oversight or regulation", “institutional oversight of AI”.
